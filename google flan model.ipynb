{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc92d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9188dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_datset_name=\"knkarthick/dialogsum\"\n",
    "\n",
    "dataset=load_dataset(huggingface_datset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c6db13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________\n",
      "Example:  1\n",
      "___________________________________________________________________________________________________\n",
      "INPUT DIALOGUE:\n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "___________________________________________________________________________________________________\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "___________________________________________________________________________________________________\n",
      "\n",
      "___________________________________________________________________________________________________\n",
      "Example:  2\n",
      "___________________________________________________________________________________________________\n",
      "INPUT DIALOGUE:\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "___________________________________________________________________________________________________\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "___________________________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices=[40, 200]\n",
    "\n",
    "dash_line=\"_\".join(\"\" for i in range(100))\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    print(dash_line)\n",
    "    print(\"Example: \", i+1)\n",
    "    print(dash_line)\n",
    "    print(\"INPUT DIALOGUE:\")\n",
    "    print(dataset[\"test\"][index][\"dialogue\"])\n",
    "    print(dash_line)\n",
    "    print(\"BASELINE HUMAN SUMMARY:\")\n",
    "    print(dataset[\"test\"][index][\"summary\"])\n",
    "    print(dash_line)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75a3f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"google/flan-t5-base\"\n",
    "\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c79e2186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88f09cea90f47afa98d3b58a21e724d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e34a6402f74a5694ea44cc869df7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da64098b31a4e5eb0694a543cd823c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4681bdcafd54794b15a48fa1449b9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd66c95",
   "metadata": {},
   "source": [
    "### Zero shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f7d373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________\n",
      "Example 1:  1\n",
      "___________________________________________________________________________________________________\n",
      "INPUT PROMPT:\n",
      "summarize the following conversation:\n",
      "    \n",
      "    #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "    \n",
      "    Summary: \n",
      "    \n",
      "___________________________________________________________________________________________________\n",
      "SUMMARY:\n",
      "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "___________________________________________________________________________________________________\n",
      "MODEL GENERATED SUMMARY:\n",
      "The train is about to leave.\n",
      "___________________________________________________________________________________________________\n",
      "Example 1:  2\n",
      "___________________________________________________________________________________________________\n",
      "INPUT PROMPT:\n",
      "summarize the following conversation:\n",
      "    \n",
      "    #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "    \n",
      "    Summary: \n",
      "    \n",
      "___________________________________________________________________________________________________\n",
      "SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "___________________________________________________________________________________________________\n",
      "MODEL GENERATED SUMMARY:\n",
      "#Person1#: Have you considered upgrading your system?\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    dialogue=dataset[\"test\"][index][\"dialogue\"]\n",
    "    summary=dataset[\"test\"][index][\"summary\"]\n",
    "    \n",
    "    prompt=f'''summarize the following conversation:\n",
    "    \n",
    "    {dialogue}\n",
    "    \n",
    "    Summary: \n",
    "    '''\n",
    "    inputs= tokenizer(prompt, return_tensors=\"pt\", verbose=True)\n",
    "    output=tokenizer.decode(model.generate(inputs[\"input_ids\"], max_new_tokens=50)[0],skip_special_tokens=True)\n",
    "    \n",
    "    print(dash_line)\n",
    "    print(\"Example 1: \", i+1)\n",
    "    print(dash_line)\n",
    "    print(f\"INPUT PROMPT:\\n{prompt}\")\n",
    "    print(dash_line)\n",
    "    print(f\"SUMMARY:\\n{summary}\")\n",
    "    print(dash_line)\n",
    "    print(f\"MODEL GENERATED SUMMARY:\\n{output}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad7f78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(example_indices_full,example_indices_to_summary):\n",
    "    prompt=\"\"\n",
    "    for index in example_indices_full:\n",
    "        dialogue=dataset[\"test\"][index][\"dialogue\"]\n",
    "        summary=dataset[\"test\"][index][\"summary\"]\n",
    "        \n",
    "        prompt+=f'''\n",
    "        Dialoague: {dialogue}\n",
    "        \n",
    "        Summary: {summary}\n",
    "        '''\n",
    "    dialogue=dataset[\"test\"][example_indices_to_summary][\"dialogue\"]\n",
    "    \n",
    "    prompt+=f'''\n",
    "        Dialoague: {dialogue}\n",
    "        \n",
    "        Summary: \n",
    "        '''\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d185230",
   "metadata": {},
   "source": [
    "### One shot inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53aefd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Dialoague: #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "        \n",
      "        Summary: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "        \n",
      "        Dialoague: #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "        \n",
      "        Summary: \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "example_indices_full=[40]\n",
    "example_indices_to_summary=200\n",
    "one_shot_prompt=make_prompt(example_indices_full,example_indices_to_summary )\n",
    "\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04e8ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "___________________________________________________________________________________________________\n",
      "MODEL GENERATED SUMMARY:\n",
      "#Person1#: Have you considered upgrading your system? #Person2#: Yes, but I'm not sure what exactly I would need. #Person1#: You could add a painting program to your software.\n"
     ]
    }
   ],
   "source": [
    "summary=dataset[\"test\"][example_indices_to_summary][\"summary\"]\n",
    "\n",
    "inputs=tokenizer(one_shot_prompt,return_tensors=\"pt\")\n",
    "output=tokenizer.decode(model.generate(inputs[\"input_ids\"], max_new_tokens=50)[0],skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(f\"SUMMARY:\\n{summary}\")\n",
    "print(dash_line)\n",
    "print(f\"MODEL GENERATED SUMMARY:\\n{output}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7207d66",
   "metadata": {},
   "source": [
    "### Few shot inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d0d0a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Dialoague: #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "        \n",
      "        Summary: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "        \n",
      "        Dialoague: #Person1#: May, do you mind helping me prepare for the picnic?\n",
      "#Person2#: Sure. Have you checked the weather report?\n",
      "#Person1#: Yes. It says it will be sunny all day. No sign of rain at all. This is your father's favorite sausage. Sandwiches for you and Daniel.\n",
      "#Person2#: No, thanks Mom. I'd like some toast and chicken wings.\n",
      "#Person1#: Okay. Please take some fruit salad and crackers for me.\n",
      "#Person2#: Done. Oh, don't forget to take napkins disposable plates, cups and picnic blanket.\n",
      "#Person1#: All set. May, can you help me take all these things to the living room?\n",
      "#Person2#: Yes, madam.\n",
      "#Person1#: Ask Daniel to give you a hand?\n",
      "#Person2#: No, mom, I can manage it by myself. His help just causes more trouble.\n",
      "        \n",
      "        Summary: Mom asks May to help to prepare for the picnic and May agrees.\n",
      "        \n",
      "        Dialoague: #Person1#: Hello, I bought the pendant in your shop, just before. \n",
      "#Person2#: Yes. Thank you very much. \n",
      "#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n",
      "#Person2#: Oh, is it? \n",
      "#Person1#: Would you change it to a new one? \n",
      "#Person2#: Yes, certainly. You have the receipt? \n",
      "#Person1#: Yes, I do. \n",
      "#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n",
      "#Person1#: Thank you so much. \n",
      "        \n",
      "        Summary: #Person1# wants to change the broken pendant in #Person2#'s shop.\n",
      "        \n",
      "        Dialoague: #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "        \n",
      "        Summary: \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "example_indices_full1=[40, 80, 120]\n",
    "example_indices_to_summary1=200\n",
    "one_shot_prompt1=make_prompt(example_indices_full1,example_indices_to_summary1 )\n",
    "\n",
    "print(one_shot_prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5c101d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "___________________________________________________________________________________________________\n",
      "MODEL GENERATED SUMMARY:\n",
      "#Person1#: Have you considered upgrading your system? #Person2#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software\n"
     ]
    }
   ],
   "source": [
    "summary=dataset[\"test\"][example_indices_to_summary][\"summary\"]\n",
    "\n",
    "inputs=tokenizer(one_shot_prompt1,return_tensors=\"pt\")\n",
    "output=tokenizer.decode(model.generate(inputs[\"input_ids\"], max_new_tokens=50)[0],skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(f\"SUMMARY:\\n{summary}\")\n",
    "print(dash_line)\n",
    "print(f\"MODEL GENERATED SUMMARY:\\n{output}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e0ec1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "___________________________________________________________________________________________________\n",
      "MODEL GENERATED SUMMARY:\n",
      "#Person1#: Have you considered upgrading your system? #Person2#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software\n"
     ]
    }
   ],
   "source": [
    "generation_config=GenerationConfig(max_new_tokens=50)\n",
    "\n",
    "inputs=tokenizer(one_shot_prompt1,return_tensors=\"pt\")\n",
    "output=tokenizer.decode(model.generate(inputs[\"input_ids\"], generation_config=generation_config)[0],skip_special_tokens=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"SUMMARY:\\n{summary}\")\n",
    "print(dash_line)\n",
    "print(f\"MODEL GENERATED SUMMARY:\\n{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76090eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db03723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3722327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
